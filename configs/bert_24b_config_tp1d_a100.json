{
    "model": {
        "type": "bert_24b",
        "flash_attention": true
    },
    "hyperparameter": {
        "batch_size": 12,
        "global_batch_size": 480,
        "learning_rate": 0.0001,
        "min_lr": 0.00001,
        "num_epochs": 2,
        "steps_per_epoch": 20,
        "warmup_steps": 20
    },
    "fp16": {
        "initial_scale": 1.0
    },
    "gradient_checkpoint": false,
    "clip_grad_norm": 1.0,
    "parallel": {
        "tensor": {
            "mode": "1d",
            "size": 8
        }
    }
}